[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Greenbook section III.A.1. Calculation of Vegetation Water Requirement",
    "section": "",
    "text": "Purpose\nThe Water Agreement and Green Book established procedures to determine which LADWP pumping wells can be operated based vegetation water requirements. As part of the monitoring effort for the Agreement, the Water Department regularly measures soil water content and vegetation leaf area index (with LADWP) to estimate vegetation water needs at 22 permanent sites located in wellfields and eight sites in control areas. Soil water monitoring is conducted monthly and vegetation monitoring is conducted annually in June.\nEach monitoring site is linked to one or more LADWP pumping wells.\nOn July 1 and October 1, if the soil water is insufficient to meet the needs of the vegetation at a site, the linked pumping wells cannot be operated. The wells must remain off until the soil water exceeds the amount required by the vegetation at the time the wells went off. This is referred to as the On/Off management strategy. During much of the period since this management was implemented in 1990, LADWP has not operated numerous wells in On status in accordance with subsequent agreements with the County.\nThis website documents the code used to calculate the vegetation water requirements from the annual vegetation monitoring at on/off permanent vegetation transects.\nThe targets package provides tools to construct a dependency aware analysis pipeline allowing automatic tracking of upstream changes to files which informs which processes are out of date and limits updates to only those downstream dependencies.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.3     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nThere were 13 warnings (use warnings() to see them)\n\n\n\n\n\n\nThe ‘Stems’ (circles) represent data file input, intermediate and final data wrangling transformations with computations of LAI and VWR. The functions (triangles) take an input stem and output a new stem shown by linkages in the pipeline. Color green indicates the stems and functions are up to date - grey indicates changes have been made since the last tar_make() call.\nOnce the targets pipeline is made, the targets are stored in _targets/objects. These objects can be read into quarto or rmarkdown documents using tar_read().\n\nCodecYear &lt;- tar_read(cYear)# current year\n\n\nData Ingestion\nPoint frame data is currently entered into excel spreadsheets on field tablets, and species level totals are copy/pasted into a wide format spreadsheet with site as rows and species as columns. This format was necessary in the past becaue the excel formulas were set up in that way. The number represents number of hits for each species in 3 dimensions every 30 cm for 334 pin drops.\n\nCodetar_read(pointframe_wide) %&gt;% datatable(caption = paste0('Point frame data entered in wide format in ',cYear,\".\"),filter = c(\"top\"),options = list(\n  pageLength = 5, autoWidth = FALSE)) \n\n\n\n\n\n\nThe wide data is transformed into long format (tidy data). It should be noted here that the incoming wide format is an unnecessary intermediate format - a byproduct of doing column-wise calculations in the VWR excel calculator. Going forward, programmatically extracting the site-species-count rows into long format from the data entry spreadsheet should be a goal of the end to end data pipeline.\n\nCodetar_read(pointframe_long) %&gt;% arrange(site,species) %&gt;% datatable(caption = paste0('Tidy point-frame data (site-species unique row combos) obtained with pivot_longer() function on wide input data above. Data updated in ',cYear,\".\"),filter = c(\"top\"),options = list(\n  pageLength = 7, autoWidth = FALSE)) \n\n\n\n\n\n\n\nCodetar_read(sitesoil) %&gt;% datatable(caption = paste0(\"Site soil texture designation (silt or sand).\"),filter = c(\"top\"),options = list(\n  pageLength = 5, autoWidth = FALSE))\n\n\n\nCodetar_read(vwrmax_lookt) %&gt;% datatable(caption = paste0('Species-level leaf area index (LAI) for July 1, ',cYear,\", and VWR max for each period (July or October), site soil texture designation (silt or sand) affecting plant available water.\"),filter = c(\"top\"),options = list(\n  pageLength = 5, autoWidth = FALSE))%&gt;% formatRound('lai',2)\n\n\n\nCodetar_read(vwr) %&gt;% filter(lai&gt;0) %&gt;%  datatable(caption = paste0('Species-level VWR at each site computed from multiplying LAI by VWR max for each period (July or October)'),filter = c(\"top\"),options = list(\n  pageLength = 5, autoWidth = FALSE))%&gt;% formatRound(c('lai','vwr_at_lai_max','vwr'),2)\n\n\nWeighted average VWR/LAI\nThe sum of vwr for six species divided by sum of lai for six co-ocurring species provides estimates for VWRmax for the OTHER category.\nThis value is multiplied by the LAI of the OTHER column to obtain VWR for OTHER.\n\nCodetar_read(weighted.avg)%&gt;% datatable(caption = paste0('Site-level weighted average VWR/LAI for ',cYear,\", used as VWR max for OTHER species category for each period ().\"),filter = c(\"top\"),options = list(\n  pageLength = 5, autoWidth = FALSE))%&gt;% formatRound(c('w_avg_vwr_per_lai'),2)\n\n\n\n\n\n\nSpecies level VWR\nHere we combine the site VWRs from the six dominant species and from the OTHER column into a single column.\n\nCode# join weighted avg VWR/LAI to vwr by site, species, period, and combined \ntar_read(vwr.total) %&gt;% filter(all.hits &gt; 0) %&gt;% select(site,period,species,lai,total.vwr) %&gt;%  datatable(caption = paste0(\"Total VWR for six dominant species and other species combined into one column\"),filter = c(\"top\"),options = list(\n  pageLength = 5, autoWidth = FALSE)) %&gt;% formatRound(c('lai','total.vwr'),2)\n\n\n\n\n\n\nSite-level VWR\n\nCodetar_read(vwr.wide.period) %&gt;% datatable(caption = paste0('Vegetation water requirements (cm) July 1 (half year) and Oct 1 (full year), for ',cYear,', calculated according to Greenbook section III.A.1.'),filter = c(\"top\"),options = list(\n  pageLength = 5, autoWidth = FALSE),colnames = c('Site','July','October')) %&gt;% formatRound(c('july','oct'),2) \n\n\n\n\n\n\nLocations of Monitoring Sites\nSites can be viewed by using the left pull out arrow and selecting a monitoring site to zoom to.\n\n\n\n\nCitationBibTeX citation:@report{2024,\n  author = {},\n  publisher = {Inyo County Water Department},\n  title = {Greenbook Section {III.A.1.} {Calculation} of {Vegetation}\n    {Water} {Requirement}},\n  date = {2024-05-24},\n  url = {https://github.com/inyo-gov/vegetation-water-requirement},\n  langid = {en}\n}\nFor attribution, please cite this work as:\n“Greenbook Section III.A.1. Calculation of Vegetation Water\nRequirement.” 2024. Green Book Section III On/Off Pumping\nManagement. Inyo County Water Department. https://github.com/inyo-gov/vegetation-water-requirement."
  },
  {
    "objectID": "targets_pipeline_instruct.html",
    "href": "targets_pipeline_instruct.html",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "Ensure you have the targets package installed and loaded in your R environment.\ninstall.packages(\"targets\")\nlibrary(targets)\n\n\n\ninclude the necessary files:\nR/: A directory for custom R scripts and functions. _targets.R: The pipeline script where you define your targets and workflow. Step 3: Write Your Target Script (_targets.R) Create a file named _targets.R at the root of your project directory. This file defines your pipeline using the targets package. Here’s an example structure:\n\n\n\nCreate a file named _targets.R at the root of your project directory. This file defines your pipeline using the targets package. Here’s an example structure:\nlibrary(targets)\n\n# Source custom functions\ntar_source(\"R/functions.R\")\n\n# Define the list of targets\nlist(\n  tar_target(\n    raw_data,\n    read.csv(\"data/raw_data.csv\")\n  ),\n  tar_target(\n    cleaned_data,\n    clean_data(raw_data)\n  ),\n  tar_target(\n    analysis_result,\n    analyze_data(cleaned_data)\n  ),\n  tar_target(\n    report,\n    rmarkdown::render(\"report.Rmd\", params = list(data = analysis_result)),\n    format = \"file\"\n  )\n)\n\n\n\ndirectory. For instance, you might have a file named functions.R with the following content:\nclean_data &lt;- function(data) {\n  # Cleaning steps\n  data &lt;- na.omit(data)\n  return(data)\n}\n\nanalyze_data &lt;- function(data) {\n  # Analysis steps\n  result &lt;- summary(data)\n  return(result)\n}\n\n\n\ndata/raw_data.csv) and any R Markdown files (e.g., report.Rmd) properly set up.\nStep 6: Build the Pipeline Use the tar_make() function to build and execute the pipeline. This function will run all the targets in the correct order based on their dependencies.\ntar_make()\n\n\n\n\nand its dependencies. Use tar_meta() to check the status of targets and their metadata. Use tar_outdated() to check which targets are outdated and need to be rerun.\n\n\n\nscript and functions as needed. The targets package will only rerun the necessary parts of the pipeline based on changes, making the process efficient.\n\n\n\n\nSet Up Project Directory:\n\nmy_project/\n├── R/\n│   └── functions.R\n├── data/\n│   └── raw_data.csv\n├── report.qmd\n└── _targets.R\n\nWrite _targets.R:\n\n\nlibrary(targets)\n\ntar_source(\"R/functions.R\")\n\nlist(\n  tar_target(\n    raw_data,\n    read.csv(\"data/raw_data.csv\")\n  ),\n  tar_target(\n    cleaned_data,\n    clean_data(raw_data)\n  ),\n  tar_target(\n    analysis_result,\n    analyze_data(cleaned_data)\n  ),\n  tar_target(\n    report,\n    quarto::quarto_render(\"report.Rmd\", params = list(data = analysis_result)),\n    format = \"file\"\n  )\n)\n\nCreate R/functions.R:\n\nclean_data &lt;- function(data) {\n  data &lt;- na.omit(data)\n  return(data)\n}\n\nanalyze_data &lt;- function(data) {\n  result &lt;- summary(data)\n  return(result)\n}\n\nRun the Pipeline:\n\ntar_make()\nBy following these steps, you can set up and build a pipeline using the targets package in R, facilitating reproducible and efficient workflows."
  },
  {
    "objectID": "targets_pipeline_instruct.html#step-1-install-and-load-the-targets-package",
    "href": "targets_pipeline_instruct.html#step-1-install-and-load-the-targets-package",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "Ensure you have the targets package installed and loaded in your R environment.\ninstall.packages(\"targets\")\nlibrary(targets)"
  },
  {
    "objectID": "targets_pipeline_instruct.html#step-2-set-up-your-project-directory-organize-your-project-directory-to",
    "href": "targets_pipeline_instruct.html#step-2-set-up-your-project-directory-organize-your-project-directory-to",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "include the necessary files:\nR/: A directory for custom R scripts and functions. _targets.R: The pipeline script where you define your targets and workflow. Step 3: Write Your Target Script (_targets.R) Create a file named _targets.R at the root of your project directory. This file defines your pipeline using the targets package. Here’s an example structure:"
  },
  {
    "objectID": "targets_pipeline_instruct.html#step-3-write-your-target-script-_targets.r",
    "href": "targets_pipeline_instruct.html#step-3-write-your-target-script-_targets.r",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "Create a file named _targets.R at the root of your project directory. This file defines your pipeline using the targets package. Here’s an example structure:\nlibrary(targets)\n\n# Source custom functions\ntar_source(\"R/functions.R\")\n\n# Define the list of targets\nlist(\n  tar_target(\n    raw_data,\n    read.csv(\"data/raw_data.csv\")\n  ),\n  tar_target(\n    cleaned_data,\n    clean_data(raw_data)\n  ),\n  tar_target(\n    analysis_result,\n    analyze_data(cleaned_data)\n  ),\n  tar_target(\n    report,\n    rmarkdown::render(\"report.Rmd\", params = list(data = analysis_result)),\n    format = \"file\"\n  )\n)"
  },
  {
    "objectID": "targets_pipeline_instruct.html#step-4-create-custom-functions-place-any-custom-functions-in-the-r",
    "href": "targets_pipeline_instruct.html#step-4-create-custom-functions-place-any-custom-functions-in-the-r",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "directory. For instance, you might have a file named functions.R with the following content:\nclean_data &lt;- function(data) {\n  # Cleaning steps\n  data &lt;- na.omit(data)\n  return(data)\n}\n\nanalyze_data &lt;- function(data) {\n  # Analysis steps\n  result &lt;- summary(data)\n  return(result)\n}"
  },
  {
    "objectID": "targets_pipeline_instruct.html#step-5-define-your-data-and-report-ensure-you-have-your-data-e.g.",
    "href": "targets_pipeline_instruct.html#step-5-define-your-data-and-report-ensure-you-have-your-data-e.g.",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "data/raw_data.csv) and any R Markdown files (e.g., report.Rmd) properly set up.\nStep 6: Build the Pipeline Use the tar_make() function to build and execute the pipeline. This function will run all the targets in the correct order based on their dependencies.\ntar_make()"
  },
  {
    "objectID": "targets_pipeline_instruct.html#step-7-monitor-and-debug-use-tar_visnetwork-to-visualize-the-pipeline",
    "href": "targets_pipeline_instruct.html#step-7-monitor-and-debug-use-tar_visnetwork-to-visualize-the-pipeline",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "and its dependencies. Use tar_meta() to check the status of targets and their metadata. Use tar_outdated() to check which targets are outdated and need to be rerun."
  },
  {
    "objectID": "targets_pipeline_instruct.html#step-8-incremental-updates-modify-your-target",
    "href": "targets_pipeline_instruct.html#step-8-incremental-updates-modify-your-target",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "script and functions as needed. The targets package will only rerun the necessary parts of the pipeline based on changes, making the process efficient."
  },
  {
    "objectID": "targets_pipeline_instruct.html#example-workflow-set-up-project-directory",
    "href": "targets_pipeline_instruct.html#example-workflow-set-up-project-directory",
    "title": "Building a Pipeline with targets in R",
    "section": "",
    "text": "Set Up Project Directory:\n\nmy_project/\n├── R/\n│   └── functions.R\n├── data/\n│   └── raw_data.csv\n├── report.qmd\n└── _targets.R\n\nWrite _targets.R:\n\n\nlibrary(targets)\n\ntar_source(\"R/functions.R\")\n\nlist(\n  tar_target(\n    raw_data,\n    read.csv(\"data/raw_data.csv\")\n  ),\n  tar_target(\n    cleaned_data,\n    clean_data(raw_data)\n  ),\n  tar_target(\n    analysis_result,\n    analyze_data(cleaned_data)\n  ),\n  tar_target(\n    report,\n    quarto::quarto_render(\"report.Rmd\", params = list(data = analysis_result)),\n    format = \"file\"\n  )\n)\n\nCreate R/functions.R:\n\nclean_data &lt;- function(data) {\n  data &lt;- na.omit(data)\n  return(data)\n}\n\nanalyze_data &lt;- function(data) {\n  result &lt;- summary(data)\n  return(result)\n}\n\nRun the Pipeline:\n\ntar_make()\nBy following these steps, you can set up and build a pipeline using the targets package in R, facilitating reproducible and efficient workflows."
  }
]